{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efefea83-782b-4061-9da7-9f8c716ddb3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cptdl as dl \n",
    "import cptio as cio \n",
    "import cptcore as cc \n",
    "import cptextras as ce \n",
    "\n",
    "\n",
    "import xarray as xr \n",
    "import datetime as dt \n",
    "from pathlib import Path \n",
    "import matplotlib.pyplot as plt \n",
    "import cartopy.crs as ccrs\n",
    "import numpy as np\n",
    "\n",
    "import cartopy.feature as cartopyFeature\n",
    "\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "41d40473-cb8a-4958-9806-0046318a50f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from requests import HTTPError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28ef6b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_name = \"pycpt_GTM_EPS_PRECP\"  \n",
    "case_directory = f'/home/guillermo/DEV/EPS/cases/{case_name}'\n",
    "os.mkdir(case_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de685a19-6f43-4696-9ee3-52b728caf00e",
   "metadata": {
    "editable": false
   },
   "source": [
    "#### Parameters - This cell defines the parameters of your analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d016514-ce88-47b2-a369-ef38943503c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MOS = 'CCA'\n",
    "predictor_names = [ \n",
    "    \"CCSM4.PRCP\", \n",
    "    \"CanSIPSIC3.PRCP\",\n",
    "    \"GEOSS2S.PRCP\",\n",
    "    \"SPEAR.PRCP\", \n",
    "    \"CFSv2.PRCP\",\n",
    "    \n",
    "    \"SEAS5.PRCP\",\n",
    "    \"METEOFRANCE8.PRCP\",\n",
    "    \"GLOSEA6.PRCP\"\n",
    "]\n",
    "\n",
    "predictand_name = 'UCSB.PRCP' # UCSB es CHIRPS v2p0\n",
    "\n",
    "# use dl.observations.keys() to see all options for predictand \n",
    "# and dl.hindcasts.keys() to see all options for predictors\n",
    "# make sure your first_year & final_year are compatible with \n",
    "# your selections for your predictors and predictands "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "815ce153-c941-4349-8584-5ec7757e5a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DISPONIBILIDAD DE DATOS HINDCAST PARA LOS MODELOS SELECCIONADOS:\n",
      "\t CCSM4 {'start': '1982-01-01', 'end': -1} {'start': '1982-01-01', 'end': -1}\n",
      "\t CanSIPSIC3 {'start': '1980-01-01', 'end': '2020-12-01'} {'start': '2021-10-01', 'end': -1}\n",
      "\t GEOSS2S {'start': '1981-02-01', 'end': -1} {'start': '2017-02-01', 'end': -1}\n",
      "\t SPEAR {'start': '1991-01-01', 'end': -1} {'start': '2020-12-01', 'end': -1}\n",
      "\t CFSv2 {'start': '1982-01-01', 'end': -1} {'start': '2011-04-01', 'end': -1}\n",
      "\t SEAS5 {'start': '1981-01-01', 'end': '2016-12-01'} {'start': '2017-09-01', 'end': -1}\n",
      "\t METEOFRANCE8 {'start': '1993-01-01', 'end': '2016-12-01'} {'start': '2021-07-01', 'end': -1}\n",
      "\t GLOSEA6 {'start': '1993-01-01', 'end': '2016-12-01'} {'start': '2021-03-01', 'end': -1}\n",
      "Rango de datos: 1993-01-01  -  2016-12-01\n"
     ]
    }
   ],
   "source": [
    "print(\"DISPONIBILIDAD DE DATOS HINDCAST PARA LOS MODELOS SELECCIONADOS:\")\n",
    "starts = []\n",
    "ends = []\n",
    "for model in [pred.split(\".\")[0] for pred in predictor_names]:\n",
    "    print(\"\\t\", model, dl.metadata[model][\"hindcast_limits\"], dl.metadata[model][\"forecast_limits\"])\n",
    "    starts.append(datetime.date.fromisoformat(dl.metadata[model][\"hindcast_limits\"][\"start\"]))\n",
    "    if dl.metadata[model][\"hindcast_limits\"][\"end\"] != -1:\n",
    "        ends.append(datetime.date.fromisoformat(dl.metadata[model][\"hindcast_limits\"][\"end\"]))\n",
    "print(\"Rango de datos de Hindcast:\", max(starts), \" - \", min(ends))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c476b1-362d-4b3f-9df9-28a653e26029",
   "metadata": {},
   "source": [
    "23 a√±os disponibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "076ded6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "download_args = { \n",
    "   # 'fdate':\n",
    "   #   the initialization date of the model forecasts / hindcasts\n",
    "   #   this field is defined by a python datetime.datetime object\n",
    "   #   for example: dt.datetime(2022, 5, 1) # YYYY, MM, DD as integers\n",
    "   #   The year field is only used for forecasts, otherwise ignored\n",
    "   #   The day field is only used in subseasonal forecasts, otherwise ignored\n",
    "   #   The month field is an integer representing a month - ie, May=5\n",
    "  'fdate':  dt.datetime(2021, 4, 1), #dt.datetime(2022, 6, 1),  \n",
    "    \n",
    "   # 'first_year':\n",
    "   #   the first year of hindcasts you want. **NOT ALL MODELS HAVE ALL YEARS**\n",
    "   #   double check that your model has hindcast data for all years in [first_year, final_year]\n",
    "   #   This field is defined by a python integer representing a year, ie: 1993\n",
    "  'first_year': 1993,  \n",
    "    \n",
    "   # 'final_year':\n",
    "   #   the final year of hindcasts you want. **NOT ALL MODELS HAVE ALL YEARS**\n",
    "   #   double check that your model has hindcast data for all years in [first_year, final_year]\n",
    "   #   This field is defined by a python integer representing a year, ie: 2016\n",
    "  'final_year': 2016,  \n",
    "    \n",
    "   # 'predictor_extent':\n",
    "   #   The geographic bounding box of the climate model data you want to download\n",
    "   #   This field is defined by a python dictionary with the keys \"north\", \"south\",\n",
    "   #   \"east\", and \"west\", each of which maps to a python integer representing the \n",
    "   #   edge of a bounding box. i.e., \"north\" will be the northernmost boundary,\n",
    "   #   \"south\" the southernmost boundary. Example: {\"north\": 90, \"south\": 90, \"east\": 0, \"west\": 180}\n",
    "  'predictor_extent': {\n",
    "    'east':  -70,\n",
    "    'west': -120, \n",
    "    'north': 40,\n",
    "    'south': -5\n",
    "  }, \n",
    "    \n",
    "   # 'predictand_extent':\n",
    "   #   The geographic bounding box of the observation data you want to download\n",
    "   #   This field is defined by a python dictionary with the keys \"north\", \"south\",\n",
    "   #   \"east\", and \"west\", each of which maps to a python integer representing the \n",
    "   #   edge of a bounding box. i.e., \"north\" will be the northernmost boundary,\n",
    "   #   \"south\" the southernmost boundary. Example: {\"north\": 90, \"south\": 90, \"east\": 0, \"west\": 180}\n",
    "  'predictand_extent': {\n",
    "    'east':  -70,\n",
    "    'west': -120, \n",
    "    'north': 40,\n",
    "    'south': -5\n",
    "  },\n",
    "\n",
    "    \n",
    "   # 'lead_low': \n",
    "   #   the number of months from the first of the initialization month to the center of \n",
    "   #   the first month included in the target period. Always an integer + 0.5. \n",
    "   #   this field is defined by a python floating point number \n",
    "   #   for example  a lead-1 forecast would use lead_low=1.5, if you want init=may, target=Jun-..\n",
    "  'lead_low': 1.5,\n",
    "    \n",
    "   # 'lead_high': \n",
    "   #   the number of months from the first of the initialization month to the center of \n",
    "   #   the last month included in the target period. Always an integer + 0.5. \n",
    "   #   this field is defined by a python floating point number \n",
    "   #   for example  a forecast initialized in may, whose target period ended in Aug, \n",
    "   #   would use lead_high=3.5\n",
    "  'lead_high': 3.5, \n",
    "    \n",
    "   # 'target': \n",
    "   #   Mmm-Mmm indicating the months included in the target period of the forecast. \n",
    "   #   this field is defined by a python string, with two three-letter month name abbreviations \n",
    "   #   whose first letters are capitalized, and all other letters are lowercase\n",
    "   #   and who are separated by a dash character. \n",
    "   #   for example, if you wanted a JJA target period, you would use 'Jun-Aug'\n",
    "  'target': 'May-Jul',#'Jul-Sep',\n",
    "    \n",
    "   # 'filetype':\n",
    "   #   the filetype to be downloaded. for now, it saves a lot of headache just to set this equal\n",
    "   #   to 'cptv10.tsv' which is a boutique plain-text CPT filetype based on .tsv + metadata\n",
    "  'filetype': 'cptv10.tsv'\n",
    "}\n",
    "\n",
    "cpt_args = { \n",
    "    'transform_predictand': None,  # transformation to apply to the predictand dataset - None, 'Empirical', 'Gamma'\n",
    "    'tailoring': None,  # tailoring None, 'Anomaly', 'StdAnomaly', or 'SPI' (SPI only available on Gamma)\n",
    "    'cca_modes': (1,3), # minimum and maximum of allowed CCA modes \n",
    "    'x_eof_modes': (1,5), # minimum and maximum of allowed X Principal Componenets \n",
    "    'y_eof_modes': (1,5), # minimum and maximum of allowed Y Principal Components \n",
    "    'validation': 'crossvalidation', # the type of validation to use - crossvalidation, retroactive, or doublecrossvalidation\n",
    "    'drymask': False, #whether or not to use a drymask of -999\n",
    "    'scree': True, # whether or not to save % explained variance for eof modes\n",
    "    'crossvalidation_window': 5,  # number of samples to leave out in each cross-validation step \n",
    "    'synchronous_predictors': True, # whether or not we are using 'synchronous predictors'\n",
    "}\n",
    "\n",
    "\n",
    "force_download = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c288937d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#extracting domain boundaries and create house keeping\n",
    "domain = download_args['predictor_extent']\n",
    "e,w,n,s = domain.values()\n",
    "\n",
    "domainFolder = f\"{w}W-{e}E_to_{s}S-{n}N\"\n",
    "\n",
    "domainDir = f'{case_directory}/{domainFolder}'\n",
    "os.makedirs(case_directory, exist_ok=True)\n",
    "dataDir = f'{case_directory}/{domainFolder}/data'\n",
    "os.makedirs(dataDir, exist_ok=True)\n",
    "figDir = f'{case_directory}/{domainFolder}/figures'\n",
    "os.makedirs(figDir, exist_ok=True)\n",
    "outputDir = f'{case_directory}/{domainFolder}/output'\n",
    "os.makedirs(outputDir, exist_ok=True)\n",
    "config_file = ce.save_configuration(case_directory+'/.config', download_args, cpt_args, MOS, predictor_names, predictand_name )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaabc359-315e-44ac-a861-c41de4a61d04",
   "metadata": {
    "editable": false
   },
   "source": [
    "#### Download Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8716b528-58f4-4995-9dd7-fc8af7535709",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fdate': datetime.datetime(2021, 4, 1, 0, 0), 'first_year': 1993, 'final_year': 2016, 'predictor_extent': {'east': -70, 'west': -120, 'north': 40, 'south': -5}, 'predictand_extent': {'east': -70, 'west': -120, 'north': 40, 'south': -5}, 'lead_low': 1.5, 'lead_high': 3.5, 'target': 'May-Jul', 'filetype': 'cptv10.tsv'}\n",
      "{'fdate': datetime.datetime(2021, 4, 1, 0, 0), 'first_year': 1993, 'final_year': 2016, 'predictor_extent': {'east': -70, 'west': -120, 'north': 40, 'south': -5}, 'predictand_extent': {'east': -70, 'west': -120, 'north': 40, 'south': -5}, 'lead_low': 1.5, 'lead_high': 3.5, 'target': 'May-Jul', 'filetype': 'cptv10.tsv'}\n"
     ]
    }
   ],
   "source": [
    "# Deal with \"Cross-year issues\" where either the target season crosses Jan 1 (eg DJF), \n",
    "# or where the forecast initialization is in the calendar year before the start of the target season\n",
    "# (eg JFM from Dec 1 sart)\n",
    "\n",
    "fmon=download_args['fdate'].month\n",
    "tmon1 = fmon + download_args['lead_low'] # first month of the target season\n",
    "tmon2 = fmon + download_args['lead_high'] # last month of the target season\n",
    "download_args_obs = download_args.copy()\n",
    "\n",
    "\n",
    "# For when the target season crossing Jan 1 (eg DJF)\n",
    "# (i.e., when target season starts in the same calendar year as the forecast init \n",
    "# and ends in the following calendar year)\n",
    "# Here the final year of the obs dataset needs to be incremented by 1.\n",
    "if tmon1 <= 12.5 and tmon2 > 12.5:\n",
    "    download_args_obs['final_year'] +=1    \n",
    "\n",
    "# For JFM, FMA .. with forecast initialization in the previous year.\n",
    "# (i.e., when target season starts in the calendar year after the forecast init.)\n",
    "# Here both the first and final year of the obs dataset need to be incremented by 1.\n",
    "if tmon1 > 12.5: \n",
    "    download_args_obs['first_year'] +=1\n",
    "    download_args_obs['final_year'] +=1 \n",
    "    \n",
    "print(download_args) \n",
    "print(download_args_obs)\n",
    "\n",
    "if not os.path.exists(f'{dataDir}/{predictand_name}.nc') or force_download:\n",
    "    Y = dl.download(dl.observations[predictand_name], \n",
    "                    f'{dataDir}/{predictand_name}.tsv', \n",
    "                    **download_args_obs, \n",
    "                    verbose=True, \n",
    "                    use_dlauth=False)\n",
    "    Y = getattr(Y, [i for i in Y.data_vars][0])\n",
    "    Y.to_netcdf(f'{dataDir}/{predictand_name}.nc')\n",
    "else:\n",
    "    Y = xr.open_dataset(f'{dataDir}/{predictand_name}.nc')\n",
    "    Y = getattr(Y, [i for i in Y.data_vars][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd27852b-c8d3-4ade-83b3-5caf357546db",
   "metadata": {
    "editable": false
   },
   "source": [
    "#### Download Hindcast Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ad3358da-e678-40f9-87d3-1488d32ae70e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# download training data \n",
    "hindcast_data = []\n",
    "for model in predictor_names: \n",
    "    if not os.path.exists(f\"{dataDir}/{model}.nc\") or force_download:\n",
    "        X = dl.download(dl.hindcasts[model], \n",
    "                        f\"{dataDir}{model}.tsv\", \n",
    "                        **download_args, \n",
    "                        verbose=True, \n",
    "                        use_dlauth=False)\n",
    "        X = getattr(X, [i for i in X.data_vars][0])\n",
    "        X.name = Y.name\n",
    "        X.to_netcdf(f\"{dataDir}/{model}.nc\")\n",
    "    else:\n",
    "        X = xr.open_dataset(f\"{dataDir}/{model}.nc\")\n",
    "        X = getattr(X, [i for i in X.data_vars][0])\n",
    "        X.name = Y.name\n",
    "    hindcast_data.append(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b9070d-ea1a-4a1a-8925-f238d48ca434",
   "metadata": {
    "editable": false
   },
   "source": [
    "#### Download Forecast Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a98531fe-b125-4b49-bd8c-97a71a8d9bbf",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL: https://iridl.ldeo.columbia.edu/SOURCES/.Models/.NMME/.COLA-RSMAS-CCSM4/.MONTHLY/.prec/S/%280000%201%20Apr%202021%29/VALUES/L/1.5/3.5/RANGEEDGES/%5BL%5D//keepgrids/average/Y/-5/40/RANGEEDGES/X/-120/-70/RANGEEDGES/%5BM%5D/average/92/mul/-999/setmissing_value/%5BX/Y%5D%5BL/S/add%5D/cptv10.tsv\n",
      "\n",
      "DOWNLOADING: [*************************] (35 KB) 0:00:00.410376\n",
      "URL: https://iridl.ldeo.columbia.edu/SOURCES/.Models/.NMME/.CanSIPS-IC3/.FORECAST/.MONTHLY/.prec/S/%280000%201%20Apr%202021%29/VALUES/L/1.5/3.5/RANGEEDGES/%5BL%5D//keepgrids/average/%5BM%5D/average/Y/-5/40/RANGEEDGES/X/-120/-70/RANGEEDGES/92/mul/-999/setmissing_value/%5BX/Y%5D%5BL/S/add%5D/cptv10.tsv\n",
      "\n",
      "ERROR: No se encontr√≥ datos de forecast para el modelo CanSIPSIC3.PRCP\n",
      "URL: https://iridl.ldeo.columbia.edu/SOURCES/.Models/.NMME/.NASA-GEOSS2S/.FORECAST/.MONTHLY/.prec/%5BM%5D/average/S/%280000%201%20Apr%202021%29/VALUES/L/1.5/3.5/RANGEEDGES/%5BL%5D//keepgrids/average/Y/-5/40/RANGEEDGES/X/-120/-70/RANGEEDGES/92/mul/-999/setmissing_value/%5BX/Y%5D%5BL/S/add%5D/cptv10.tsv\n",
      "\n",
      "DOWNLOADING: [*************************] (36 KB) 0:00:01.020308\n",
      "URL: https://iridl.ldeo.columbia.edu/SOURCES/.Models/.NMME/.GFDL-SPEAR/.FORECAST/.MONTHLY/.prec/%5BM%5D/average/S/%280000%201%20Apr%202021%29/VALUES/L/1.5/3.5/RANGEEDGES/%5BL%5D//keepgrids/average/Y/-5/40/RANGEEDGES/X/-120/-70/RANGEEDGES/92/mul/-999/setmissing_value/%5BX/Y%5D%5BL/S/add%5D/cptv10.tsv\n",
      "\n",
      "DOWNLOADING: [*************************] (35 KB) 0:00:02.251217\n",
      "URL: https://iridl.ldeo.columbia.edu/SOURCES/.Models/.NMME/.NCEP-CFSv2/.HINDCAST/.PENTAD_SAMPLES_FULL/.prec/S/%280000%201%20Apr%202021%29/VALUES/L/1.5/3.5/RANGEEDGES/%5BL%5D//keepgrids/average/Y/-5/40/RANGEEDGES/X/-120/-70/RANGEEDGES/%5BM%5D/average/92/mul/-999/setmissing_value/%5BX/Y%5D%5BL/S/add%5D/cptv10.tsv\n",
      "\n",
      "DOWNLOADING: [*************************] (35 KB) 0:00:00.718201\n",
      "URL: https://iridl.ldeo.columbia.edu/SOURCES/.EU/.Copernicus/.CDS/.C3S/.ECMWF/.SEAS5/.forecast/.prcp/S/%280000%201%20Apr%202021%29/VALUES/L/1.5/3.5/RANGEEDGES/%5BL%5D//keepgrids/average/Y/-5/40/RANGEEDGES/X/-120/-70/RANGEEDGES/%5BM%5D/average/c%3A/1000/(mm%20m-1)/%3Ac/mul/c%3A/86400/(s%20day-1)/%3Ac/mul/c%3A/92//units/(days)/def/%3Ac/mul/-999/setmissing_value/%5BX/Y%5D%5BL/S/add%5D/cptv10.tsv\n",
      "\n",
      "DOWNLOADING: [*************************] (36 KB) 0:00:01.947495\n",
      "URL: https://iridl.ldeo.columbia.edu/SOURCES/.EU/.Copernicus/.CDS/.C3S/.Meteo_France/.System8/.forecast/.prcp/S/%280000%201%20Apr%202021%29/VALUES/L/1.5/3.5/RANGEEDGES/%5BL%5D//keepgrids/average/Y/-5/40/RANGEEDGES/X/-120/-70/RANGEEDGES/%5BM%5D/average/c%3A/1000/(mm%20m-1)/%3Ac/mul/c%3A/86400/(s%20day-1)/%3Ac/mul/c%3A/92//units/(days)/def/%3Ac/mul/-999/setmissing_value/%5BX/Y%5D%5BL/S/add%5D/cptv10.tsv\n",
      "\n",
      "ERROR: No se encontr√≥ datos de forecast para el modelo METEOFRANCE8.PRCP\n",
      "URL: https://iridl.ldeo.columbia.edu/SOURCES/.EU/.Copernicus/.CDS/.C3S/.UKMO/.GloSea6-GC2/.System600/.forecast/.prcp/S/%280000%201%20Apr%202021%29/VALUES/L/1.5/3.5/RANGEEDGES/%5BL%5D//keepgrids/average/Y/-5/40/RANGEEDGES/X/-120/-70/RANGEEDGES/%5BM%5D/average/c%3A/1000/(mm%20m-1)/%3Ac/mul/c%3A/86400/(s%20day-1)/%3Ac/mul/c%3A/92//units/(days)/def/%3Ac/mul/-999/setmissing_value/%5BX/Y%5D%5BL/S/add%5D/cptv10.tsv\n",
      "\n",
      "DOWNLOADING: [*************************] (34 KB) 0:00:00.907675\n"
     ]
    }
   ],
   "source": [
    "# download forecast data \n",
    "forecast_data = []\n",
    "for model in predictor_names: \n",
    "    if not os.path.exists(f\"{dataDir}/{model}_f.nc\") or force_download:\n",
    "        try:\n",
    "            F = dl.download(dl.forecasts[model], \n",
    "                            f\"{dataDir}/{model}_f.tsv\", \n",
    "                            **download_args, \n",
    "                            verbose=True, \n",
    "                            use_dlauth=False)\n",
    "            F = getattr(F, [i for i in F.data_vars][0])\n",
    "            F.name = Y.name\n",
    "            F.to_netcdf(f\"{dataDir}{model}_f.nc\")\n",
    "        except HTTPError as httperr:\n",
    "            print(f\"ERROR: No se encontr√≥ datos de forecast para el modelo {model} {httperr}\")\n",
    "            F = None\n",
    "    else:\n",
    "        F = xr.open_dataset(f\"{dataDir}{model}_f.nc\")\n",
    "        F = getattr(F, [i for i in F.data_vars][0])\n",
    "        F.name = Y.name\n",
    "    forecast_data.append(F)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b98f41d-85fe-44ef-a57c-6605d11b0cc7",
   "metadata": {
    "editable": false
   },
   "source": [
    "#### Perform Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f6136809-d8bf-4f49-acc8-da199bb4ad21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejecutando an√°lisis del modelo:  CCSM4\n",
      "Ejecutando an√°lisis del modelo:  CanSIPSIC3\n",
      "Ejecutando an√°lisis del modelo:  GEOSS2S\n",
      "Ejecutando an√°lisis del modelo:  SPEAR\n",
      "Ejecutando an√°lisis del modelo:  CFSv2\n",
      "Ejecutando an√°lisis del modelo:  SEAS5\n",
      "Ejecutando an√°lisis del modelo:  METEOFRANCE8\n"
     ]
    },
    {
     "ename": "CPTError",
     "evalue": "\nPROCESS STATUS: ALIVE (WILL BE STOPPED)\n  last command: '311'\n  last message:'Reading data ...\n Reading /home/guillermo/.pycpt_workspace/231af297-0e34-4d0b-840f-edd05154eb36/original_predictand ...\n Reading /home/guillermo/.pycpt_workspace/231af297-0e34-4d0b-840f-edd05154eb36/original_predictor ...\n  \n Checking for missing values ...\n  \n  \n                                     Error\n  \n ERROR:  The X file contains too many missing series\n         /home/guillermo/.pycpt_workspace/231af297-0e34-4d0b-840f-edd05154eb36/original_predictor\n C\bP\bT\b \b'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCPTError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEjecutando an√°lisis del modelo: \u001b[39m\u001b[38;5;124m\"\u001b[39m, predictor_names[i]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(MOS)\u001b[38;5;241m.\u001b[39mupper() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCCA\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m      6\u001b[0m         \n\u001b[1;32m      7\u001b[0m         \u001b[38;5;66;03m# fit CCA model between X & Y and produce real-time forecasts for F \u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m         cca_h, cca_rtf, cca_s, cca_px, cca_py \u001b[38;5;241m=\u001b[39m \u001b[43mcc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanonical_correlation_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_hcst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforecast_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcpt_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcpt_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minteractive\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#         fit CCA model again between X & Y, and produce in-sample probabilistic hindcasts \u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#         this is using X in place of F, with the year coordinates changed to n+100 years\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#         because CPT does not allow you to make forecasts for in-sample data\u001b[39;00m\n\u001b[1;32m     14\u001b[0m         cca_h, cca_f, cca_s, cca_px, cca_py \u001b[38;5;241m=\u001b[39m cc\u001b[38;5;241m.\u001b[39mcanonical_correlation_analysis(model_hcst, Y, \\\n\u001b[1;32m     15\u001b[0m         F\u001b[38;5;241m=\u001b[39mce\u001b[38;5;241m.\u001b[39mredate(model_hcst, yeardelta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m48\u001b[39m), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcpt_args)\n",
      "File \u001b[0;32m~/DEV/EPS/devenv/lib/python3.10/site-packages/cptcore-1.0.11-py3.10.egg/cptcore/functional/cca.py:142\u001b[0m, in \u001b[0;36mcanonical_correlation_analysis\u001b[0;34m(X, Y, F, transform_predictand, tailoring, cca_modes, x_eof_modes, y_eof_modes, crossvalidation_window, retroactive_initial_training_period, retroactive_step, validation, drymask, scree, synchronous_predictors, cpt_kwargs, x_lat_dim, x_lon_dim, x_sample_dim, x_feature_dim, y_lat_dim, y_lon_dim, y_sample_dim, y_feature_dim, f_lat_dim, f_lon_dim, f_sample_dim, f_feature_dim, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m#initiate analysis \u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation\u001b[38;5;241m.\u001b[39mupper() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCROSSVALIDATION\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 142\u001b[0m     \u001b[43mcpt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m311\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m validation\u001b[38;5;241m.\u001b[39mupper() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDOUBLE-CROSSVALIDATION\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    144\u001b[0m     cpt\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;241m314\u001b[39m)\n",
      "File \u001b[0;32m~/DEV/EPS/devenv/lib/python3.10/site-packages/cptcore-1.0.11-py3.10.egg/cptcore/base.py:174\u001b[0m, in \u001b[0;36mCPT.write\u001b[0;34m(self, cpt_cmd)\u001b[0m\n\u001b[1;32m    172\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  last message:\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(x\u001b[38;5;241m.\u001b[39mstrip())\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkill()\n\u001b[0;32m--> 174\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CPTError(msg)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minteractive:\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28mprint\u001b[39m(x)\n",
      "\u001b[0;31mCPTError\u001b[0m: \nPROCESS STATUS: ALIVE (WILL BE STOPPED)\n  last command: '311'\n  last message:'Reading data ...\n Reading /home/guillermo/.pycpt_workspace/231af297-0e34-4d0b-840f-edd05154eb36/original_predictand ...\n Reading /home/guillermo/.pycpt_workspace/231af297-0e34-4d0b-840f-edd05154eb36/original_predictor ...\n  \n Checking for missing values ...\n  \n  \n                                     Error\n  \n ERROR:  The X file contains too many missing series\n         /home/guillermo/.pycpt_workspace/231af297-0e34-4d0b-840f-edd05154eb36/original_predictor\n C\bP\bT\b \b'\n"
     ]
    }
   ],
   "source": [
    "hcsts, fcsts, skill, pxs, pys = [], [], [], [], []\n",
    "\n",
    "for i, model_hcst in enumerate(hindcast_data):\n",
    "    print(\"Ejecutando an√°lisis del modelo: \", predictor_names[i].split(\".\")[0])\n",
    "    if str(MOS).upper() == 'CCA':\n",
    "        \n",
    "        # fit CCA model between X & Y and produce real-time forecasts for F \n",
    "        cca_h, cca_rtf, cca_s, cca_px, cca_py = cc.canonical_correlation_analysis(model_hcst, Y, \\\n",
    "        F=forecast_data[i], **cpt_args, cpt_kwargs={\"interactive\": False})\n",
    "\n",
    "#         fit CCA model again between X & Y, and produce in-sample probabilistic hindcasts \n",
    "#         this is using X in place of F, with the year coordinates changed to n+100 years\n",
    "#         because CPT does not allow you to make forecasts for in-sample data\n",
    "        cca_h, cca_f, cca_s, cca_px, cca_py = cc.canonical_correlation_analysis(model_hcst, Y, \\\n",
    "        F=ce.redate(model_hcst, yeardelta=48), **cpt_args)\n",
    "        cca_h = xr.merge([cca_h, ce.redate(cca_f.probabilistic, yeardelta=-48), ce.redate(cca_f.prediction_error_variance, yeardelta=-48)])\n",
    "        \n",
    "#         # use the in-sample probabilistic hindcasts to perform probabilistic forecast verification\n",
    "#         # warning - this produces unrealistically optimistic values \n",
    "        cca_pfv = cc.probabilistic_forecast_verification(cca_h.probabilistic, Y, **cpt_args)\n",
    "        cca_s = xr.merge([cca_s, cca_pfv])\n",
    "\n",
    "        hcsts.append(cca_h)\n",
    "        fcsts.append(cca_rtf)\n",
    "        skill.append(cca_s.where(cca_s > -999, other=np.nan))\n",
    "        pxs.append(cca_px)\n",
    "        pys.append(cca_py)\n",
    "        \n",
    "    elif str(MOS).upper() == 'PCR':\n",
    "        \n",
    "        # fit PCR model between X & Y and produce real-time forecasts for F \n",
    "        pcr_h, pcr_rtf, pcr_s, pcr_px = cc.principal_components_regression(model_hcst, Y, F=forecast_data[i], **cpt_args)\n",
    "        \n",
    "        # fit PCR model again between X & Y, and produce in-sample probabilistic hindcasts \n",
    "        # this is using X in place of F, with the year coordinates changed to n+100 years\n",
    "        # because CPT does not allow you to make forecasts for in-sample data\n",
    "        pcr_h, pcr_f, pcr_s, pcr_px = cc.principal_components_regression(model_hcst, Y, F=ce.redate(model_hcst, yeardelta=48), **cpt_args)\n",
    "        pcr_h = xr.merge([pcr_h, ce.redate(pcr_f.probabilistic, yeardelta=-48), ce.redate(pcr_f.prediction_error_variance, yeardelta=-48)])\n",
    "        \n",
    "        # use the in-sample probabilistic hindcasts to perform probabilistic forecast verification\n",
    "        # warning - this produces unrealistically optimistic values \n",
    "        pcr_pfv = cc.probabilistic_forecast_verification(pcr_h.probabilistic, Y, **cpt_args)\n",
    "        pcr_s = xr.merge([pcr_s, pcr_pfv])\n",
    "        hcsts.append(pcr_h)\n",
    "        fcsts.append(pcr_rtf)\n",
    "        skill.append(pcr_s.where(pcr_s > -999, other=np.nan))\n",
    "        pxs.append(pcr_px)\n",
    "    else:\n",
    "        # simply compute deterministic skill scores of non-corrected ensemble means \n",
    "        nomos_skill = cc.deterministic_skill(model_hcst, Y, **cpt_args)\n",
    "        skill.append(nomos_skill.where(nomos_skill > -999, other=np.nan))\n",
    "        \n",
    "    # choose what data to export here (any of the above results data arrays can be saved to netcdf)\n",
    "    if str(MOS).upper() == 'CCA':\n",
    "        cca_h.to_netcdf(f\"{outputDir}/{predictor_names[i]}_crossvalidated_cca_hindcasts.nc\")\n",
    "        if cca_rtf is not None:\n",
    "            cca_rtf.to_netcdf(f\"{outputDir}/{predictor_names[i]}_realtime_cca_forecasts.nc\")\n",
    "        cca_s.to_netcdf(f\"{outputDir}/{predictor_names[i]}_skillscores_cca.nc\")\n",
    "        cca_px.to_netcdf(f\"{outputDir}/{predictor_names[i]}_cca_x_spatial_loadings.nc\")\n",
    "        cca_py.to_netcdf(f\"{outputDir}/{predictor_names[i]}_cca_y_spatial_loadings.nc\")\n",
    "    elif str(MOS).upper() == 'PCR':\n",
    "        pcr_h.to_netcdf(f\"{outputDir}/{predictor_names[i]}_crossvalidated_pcr_hindcasts.nc\")\n",
    "        pcr_rtf.to_netcdf(f\"{outputDir}/{predictor_names[i]}_realtime_pcr_forecasts.nc\")\n",
    "        pcr_s.to_netcdf(f\"{outputDir}/{predictor_names[i]}_skillscores_pcr.nc\")\n",
    "        pcr_px.to_netcdf(f\"{outputDir}/{predictor_names[i]}_pcr_x_spatial_loadings.nc\")\n",
    "    else: \n",
    "        nomos_skill.to_netcdf(f\"{outputDir}/{predictor_names[i]}_nomos_skillscores.nc\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddfa3fc-c01b-4f52-9d32-a5a50521ae6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epsenv",
   "language": "python",
   "name": "epsenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
